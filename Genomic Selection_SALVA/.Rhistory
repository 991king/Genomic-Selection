setwd("~/GitHub/Genomic-Selection/Genomic Selection_SALVA")
# 1) Read it in R as text data frame (or tibble)
#I've open the DArT file (G,A and N) with TASSEL, I convert them into numerical and save the file as "Markers.txt":
#where 1 = presence marker, 0 = absence markers, and NA = missing value.
DArT <- as.matrix(read.table("data/Markers.txt", header = T))
View(DArT)
DArT <- as.matrix(read.table("data/DArT.txt", header = T))
# 2) Make sure NAs are properly read it.
# Calculate the % of missing value within the matrix n x m:
dim(DArT)
(sum(is.na(DArT))/(length(DArT)))*100  # there is a 5.38 % of missing data into the matrix n x m
# 3) From letters to numbers:
# By TASSEL. I've convert the hapmap format (C,A, N) to numerical format (AA = 1, aa = 0, aA = 0,5 = NA),
# TASSEL didn't recognice het. = N as 0.5, instead is NA value.
# So here I import the TASSEL markers and convert it to rrBLUP format (coded as {-1,0,1} = {aa,Aa,AA})
# Substitute 0 to -1 (homozygous minor aa)
DArT[DArT == 0] <- -1 #change 0 to -1
library(bcv)
DArT_noNA <-
impute.svd(DArT, # data matrix with missing values
k = 4, #the rank of the SVD approximation, I use k = 4 following Nazzicari, N. 2016
#tol = max(24279, 325) * 1e-10, #the convergence tolerance for the EM algorithm
maxiter = 100 #the maximum number of EM steps to take
)$x
View(DArT_noNA)
View(DArT)
View(DArT)
DArT[,1]
DArT[,0]
DArT_noNA <- rownames(DArT[,0])
DArT_noNA
DArT_noNA <-
impute.svd(DArT, # data matrix with missing values
k = 4, #the rank of the SVD approximation, I use k = 4 following Nazzicari, N. 2016
#tol = max(24279, 325) * 1e-10, #the convergence tolerance for the EM algorithm
maxiter = 100 #the maximum number of EM steps to take
)$x
rownames(DArT_noNA)
rownames(DArT_noNA) <- c(DArT[,0])
View(DArT_noNA)
rownames(DArT_noNA) <- DArT[,0]
View(DArT_noNA)
DArT_noNA <-
impute.svd(DArT, # data matrix with missing values
k = 4, #the rank of the SVD approximation, I use k = 4 following Nazzicari, N. 2016
#tol = max(24279, 325) * 1e-10, #the convergence tolerance for the EM algorithm
maxiter = 100 #the maximum number of EM steps to take
)$x
colnamesDArT <- c(DArT[,0])
DArT[,0]
colnamesDArT <- DArT[,0]
View(colnamesDArT)
View(colnamesDArT)
colnamesDArT <- as.vector(DArT[,0])
colnamesDArT <- as.vector(c(DArT[,0]))
colnamesDArT <- as.vector(c(DArT[,0]))
colnamesDArT <- as.matrix(DArT[,0])
View(colnamesDArT)
DArT[,0]
summary(DArT[,0])
View(DArT_noNA)
# 1) Load Genotypic data, DArT markers:
DArT <- as.matrix(read.table("data/DArT.txt", header = T))
View(DArT)
DArT[DArT == 0] <- -1 #change 0 to -1
DArT_rust <- DArT[-c(288, 294, 300, 320, 325), ] #Estas entradas no están evaluadas en CC así que las quito
DArT_rust_SVDI <-
impute.svd(DArT_rust, # data matrix with missing values
k = 4, #the rank of the SVD approximation, I use k = 4 following Nazzicari, N. 2016
#tol = max(24279, 325) * 1e-10, #the convergence tolerance for the EM algorithm
maxiter = 100 #the maximum number of EM steps to take
)$x
View(DArT_rust_SVDI)
#Hoy voy a probar prediction accuracy con multi trait index en lugar de solo DS en cámara y ver si se puede aplicar a campo:
#Markers:
dim(DArT_rust_SVDI)
# 4) Input phenotype. Traits in a matrix format. rows = GEN; column = trait
Pheno_rust <- as.matrix(read.xlsx(xlsxFile = "data/BLUP_field.xlsx", sep= "\t", rowNames = T, colNames = T, sheet = "BLUP_GS_rust"))
library(openxlsx)
# 4) Input phenotype. Traits in a matrix format. rows = GEN; column = trait
Pheno_rust <- as.matrix(read.xlsx(xlsxFile = "data/BLUP_field.xlsx", sep= "\t", rowNames = T, colNames = T, sheet = "BLUP_GS_rust"))
head(Pheno_rust)
dim(Pheno_rust)
dim(DArT_rust_SVDI)
#Pheno:
dim(Pheno_rust)
library(rrBLUP)
traits = 1
cycles = 500
IC1_accuracy = matrix(nrow = cycles, ncol = traits)
for (r in 1:cycles) {
train = as.matrix(sample(1:320, 224))
test = setdiff(1:320, train)
Pheno_train = Pheno_rust[train, ]
m_train = DArT_rust_SVDI[train, ]
Pheno_valid = Pheno_rust[test, ]
m_valid = DArT_rust_SVDI[test, ]
IC1 = (Pheno_train[, 12])
IC1_answer <- mixed.solve(IC1, Z = m_train, K = NULL, SE = F, return.Hinv = F)
u = IC1_answer$u
e = as.matrix(u)
pred_IC1_valid = m_valid %*% e
pred_IC1 = pred_IC1_valid[, 1] + IC1_answer$beta
pred_IC1
IC1_valid = Pheno_valid[, 12]
IC1_accuracy[r, 1] <-  cor(pred_IC1_valid, IC1_valid, use = "complete")
}
mean(IC1_accuracy)
#I_cc_FAI as IC2:
traits = 1
cycles = 500
IC2_accuracy = matrix(nrow = cycles, ncol = traits)
for (r in 1:cycles) {
train = as.matrix(sample(1:320, 224))
test = setdiff(1:320, train)
Pheno_train = Pheno_rust[train, ]
m_train = DArT_rust_SVDI[train, ]
Pheno_valid = Pheno_rust[test, ]
m_valid = DArT_rust_SVDI[test, ]
IC2 = (Pheno_train[, 12])
IC2_answer <- mixed.solve(IC2, Z = m_train, K = NULL, SE = F, return.Hinv = F)
u = IC2_answer$u
e = as.matrix(u)
pred_IC2_valid = m_valid %*% e
pred_IC2 = pred_IC2_valid[, 1] + IC2_answer$beta
pred_IC2
IC2_valid = Pheno_valid[, 12]
IC2_accuracy[r, 1] <-  cor(pred_IC2_valid, IC2_valid, use = "complete")
}
mean(IC2_accuracy)
#I_cc_SH as IC3:
traits = 1
cycles = 500
IC3_accuracy = matrix(nrow = cycles, ncol = traits)
for (r in 1:cycles) {
train = as.matrix(sample(1:320, 224))
test = setdiff(1:320, train)
Pheno_train = Pheno_rust[train, ]
m_train = DArT_rust_SVDI[train, ]
Pheno_valid = Pheno_rust[test, ]
m_valid = DArT_rust_SVDI[test, ]
IC3 = (Pheno_train[, 12])
IC3_answer <- mixed.solve(IC3, Z = m_train, K = NULL, SE = F, return.Hinv = F)
u = IC3_answer$u
e = as.matrix(u)
pred_IC3_valid = m_valid %*% e
pred_IC3 = pred_IC3_valid[, 1] + IC3_answer$beta
pred_IC3
IC3_valid = Pheno_valid[, 12]
IC3_accuracy[r, 1] <-  cor(pred_IC3_valid, IC3_valid, use = "complete")
}
mean(IC3_accuracy)
cor(pred_IC3, IC3_valid, use = "complete")
cor(pred_IC3, IC3_valid, use = "complete")
cor(pred_IC3, IC3_valid, use = "complete")
plot(pred_IC3, IC3_valid)
head(Pheno_rust)
#I_cc_FAI as IC2:
traits = 1
cycles = 500
IC2_accuracy = matrix(nrow = cycles, ncol = traits)
for (r in 1:cycles) {
train = as.matrix(sample(1:320, 224))
test = setdiff(1:320, train)
Pheno_train = Pheno_rust[train, ]
m_train = DArT_rust_SVDI[train, ]
Pheno_valid = Pheno_rust[test, ]
m_valid = DArT_rust_SVDI[test, ]
IC2 = (Pheno_train[, 13])
IC2_answer <- mixed.solve(IC2, Z = m_train, K = NULL, SE = F, return.Hinv = F)
u = IC2_answer$u
e = as.matrix(u)
pred_IC2_valid = m_valid %*% e
pred_IC2 = pred_IC2_valid[, 1] + IC2_answer$beta
pred_IC2
IC2_valid = Pheno_valid[, 13]
IC2_accuracy[r, 1] <-  cor(pred_IC2_valid, IC2_valid, use = "complete")
}
mean(IC2_accuracy)
#I_cc_SH as IC3:
traits = 1
cycles = 500
IC3_accuracy = matrix(nrow = cycles, ncol = traits)
for (r in 1:cycles) {
train = as.matrix(sample(1:320, 224))
test = setdiff(1:320, train)
Pheno_train = Pheno_rust[train, ]
m_train = DArT_rust_SVDI[train, ]
Pheno_valid = Pheno_rust[test, ]
m_valid = DArT_rust_SVDI[test, ]
IC3 = (Pheno_train[, 14])
IC3_answer <- mixed.solve(IC3, Z = m_train, K = NULL, SE = F, return.Hinv = F)
u = IC3_answer$u
e = as.matrix(u)
pred_IC3_valid = m_valid %*% e
pred_IC3 = pred_IC3_valid[, 1] + IC3_answer$beta
pred_IC3
IC3_valid = Pheno_valid[, 14]
IC3_accuracy[r, 1] <-  cor(pred_IC3_valid, IC3_valid, use = "complete")
}
mean(IC3_accuracy)
plot(pred_IC3, IC3_valid)
plot(pred_IC3, IC3_valid)
plot(pred_IC3_valid, IC3_valid)
plot(pred_IC3, IC3_valid)
IC3_accuracy
df_index <- data.frame(IC1_accuracy, IC2_accuracy, IC3_accuracy)
write.xlsx(df_index, "accuracies_indixes_CC.xlsx", sep = "/t")
df_index <- as.data.frame(read.xlsx(xlsxFile = "accuracies_indixes_CC.xlsx", colNames = T))
write.xlsx(df_index, "results/accuracies_indixes_CC.xlsx", sep = "/t")
df_index <- as.data.frame(read.xlsx(xlsxFile = "results/accuracies_indixes_CC.xlsx", colNames = T))
library(tidyverse)
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot()
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot() +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw()
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = FALSE, var.equal = F,
ggsignif.args = list(textsize = 1.5, tip_length = 0.01)) +
theme(text = element_text(size = 8), plot.subtitle = element_text(size=8))
library(ggstatsplot)
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = FALSE, var.equal = F,
ggsignif.args = list(textsize = 1.5, tip_length = 0.01)) +
theme(text = element_text(size = 8), plot.subtitle = element_text(size=8))
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 1.5, tip_length = 0.01)) +
theme(text = element_text(size = 8), plot.subtitle = element_text(size=8))
ggsignif.args = list(textsize = 2, tip_length = 0.01)) +
theme(text = element_text(size = 12), plot.subtitle = element_text(size=12)
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 2, tip_length = 0.01)) +
theme(text = element_text(size = 12),
plot.subtitle = element_text(size=12))
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 2, tip_length = 0.01)) +
theme(text = element_text(size = 12),
plot.subtitle = element_text(size=12))
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 8, tip_length = 0.01)) +
theme(text = element_text(size = 11),
plot.subtitle = element_text(size=11))
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 4, tip_length = 0.01)) +
theme(text = element_text(size = 11),
plot.subtitle = element_text(size=11))
ggbetweenstats(x= Trait, y = Accuracy, data = df_index,
p.adjust.method = "bonferroni", type = "p",
bf.message = T, var.equal = T,
ggsignif.args = list(textsize = 3, tip_length = 0.01)) +
theme(text = element_text(size = 11),
plot.subtitle = element_text(size=11))
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot() +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw()
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot(aes(fill = Trait)) +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw()
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot(aes(fill = Trait)) +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw(legend. position = "none")
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot(aes(fill = Trait)) +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw(legend.position = "none")
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot(aes(fill = Trait)) +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw() +
+ theme(legend.position = "none")
ggplot(df_index, aes(x= Trait, y = Accuracy)) +
geom_boxplot(aes(fill = Trait)) +
coord_flip() +
labs(title = "Accuracy by single trait or indices",
subtitle = "500 itinerances, 70% training 30% testing",
caption = "FAI 1 = With LP50, FAI 2 = Without LP50") +
theme_bw() +
theme(legend.position = "none")
plot(pred_IC2_valid, IC2_valid)
plot(pred_IC2, IC2_valid)
mean(IC2_accuracy)
#Ahora voy a hacer lo mismo con GROAN intentando 50 rep. de 10 fold cross-validation:
library(GROAN)
wb <- createWorkbench(regressor = phenoRegressor.rrBLUP,
regressor.name = 'rrBLUP',
outfolder = "/results",
stratified = T,
reps = 50,
folds = 10)
print(wb)
str(Pheno_rust)
head(Pheno_rust)
Pheno_rust_df <- as.data.frame(Pheno_rust)
#creating a dataset
nds.no_noise.DS <- createNoisyDataset(
name = 'PEA DS, no noise',
genotypes = DArT_rust_SVDI,
phenotypes = Pheno_rust_df$DS)
View(DArT_rust_SVDI)
str(GROAN.KI$SNPs)
Marker_GROAN <- as.data.frame(DArT_rust_SVDI)
#creating a dataset
nds.no_noise.DS <- createNoisyDataset(
name = 'PEA DS, no noise',
genotypes = Marker_GROAN,
phenotypes = Pheno_rust_df$DS)
Marker_GROAN
View(Marker_GROAN)
dumb <- GROAN.AI$SNPs
View(dumb)
View(DArT_rust)
View(DArT)
#creating a dataset
nds.no_noise.DS <- createNoisyDataset(
name = 'PEA DS, no noise',
genotypes = Marker_GROAN,
phenotypes = Pheno_rust_df$DS)
#parece que hay que dejar los datos en formato {2, 1, 0}
DArT <- as.matrix(read.table("data/DArT.txt", header = T))
View(DArT)
DArT[DArT == 1] <- 2 #change 1 to 2
DArT_GROAN <- DArT[-c(288, 294, 300, 320, 325), ] #Estas entradas no están evaluadas en CC así que las quito
View(DArT_GROAN)
DArT_GROAN_SVDI <-
impute.svd(DArT_GROAN, # data matrix with missing values
k = 4, #the rank of the SVD approximation, I use k = 4 following Nazzicari, N. 2016
#tol = max(24279, 325) * 1e-10, #the convergence tolerance for the EM algorithm
maxiter = 100 #the maximum number of EM steps to take
)$x
View(DArT_GROAN_SVDI)
DArT_GROAN_SVDI <- as.data.frame(DArT_GROAN_SVDI)
#creating a dataset
nds.no_noise.DS <- createNoisyDataset(
name = 'PEA DS, no noise',
genotypes = DArT_GROAN_SVDI,
phenotypes = Pheno_rust_df$DS)
DArT_GROAN_SVDI[DArT_GROAN_SVDI >= 1.5] <- 2
DArT_GROAN_SVDI[DArT_GROAN_SVDI <= 0.5] <- 0
DArT_GROAN_SVDI[DArT_GROAN_SVDI > 0.5 & DArT_GROAN_SVDI < 1.5]<- 1
DArT_GROAN_SVDI <- as.data.frame(DArT_GROAN_SVDI)
#creating a dataset
nds.no_noise.DS <- createNoisyDataset(
name = 'PEA DS, no noise',
genotypes = DArT_GROAN_SVDI,
phenotypes = Pheno_rust_df$DS)
wb <- createWorkbench(regressor = phenoRegressor.rrBLUP,
regressor.name = 'rrBLUP',
outfolder = "/results",
stratified = T,
reps = 50,
folds = 10)
print(wb)
res.no_noise <- GROAN.run(nds.no_noise.DS, wb)
p=plotResult(res.no_noise)
p
#Create others dataset:
#I_cc_FAI_LP
nds.no_noise.FAI1<- createNoisyDataset(
name = 'PEA FAI, no noise',
genotypes = DArT_GROAN_SVDI,
phenotypes = Pheno_rust_df$I_cc_FAI_LP)
#I_cc_FAI
nds.no_noise.FAI2<- createNoisyDataset(
name = 'PEA FAI2, no noise',
genotypes = DArT_GROAN_SVDI,
phenotypes = Pheno_rust_df$I_cc_FAI)
#I_cc_SH
nds.no_noise.SH<- createNoisyDataset(
name = 'PEA SH, no noise',
genotypes = DArT_GROAN_SVDI,
phenotypes = Pheno_rust_df$I_cc_SH)
#RUN GROAN for those three with the same wb:
res.no_noise.FAI1 <- GROAN.run(nds.no_noise.FAI1, wb)
plotResult(res.no_noise.FAI1)
res.no_noise.FAI2 <- GROAN.run(nds.no_noise.FAI2, wb)
plotResult(res.no_noise.FAI2)
res.no_noise.SH <- GROAN.run(nds.no_noise.SH, wb)
plotResult(res.no_noise.SH)
res.no_noise$pearson
mean(res.no_noise$pearson)
mean(res.no_noise$spearman)
mean(res.no_noise$pearson)
#RUN GROAN for those three with the same wb:
mean(res.no_noise$pearson)
mean(res.no_noise.FAI1$pearson)
mean(res.no_noise.FAI2$pearson)
mean(res.no_noise.SH$pearson)
res.total1 <- rbind(res.no_noise, res.no_noise.FAI1, res.no_noise.FAI2, res.no_noise.SH)
plotResult(res.total1)
#creating the BL regressor:
library(BGLR)
wb2 <- createWorkbench(phenoRegressor.BGLR,
regressor.name = 'Bayesian Lasso',
type = 'BL',
stratified = T,
reps = 50,
folds = 10)
wb2 <- createWorkbench(phenoRegressor.BGLR,
regressor.name = 'Bayesian Lasso',
type = 'BL',
stratified = T,
reps = 50,
folds = 10)
print(wb2)
wb2 <- createWorkbench(phenoRegressor.BGLR,
regressor.name = 'Bayesian Lasso',
outfolder = "/results",
type = 'BL',
stratified = T,
reps = 50,
folds = 10)
wb2 <- createWorkbench(phenoRegressor.BGLR,
regressor.name = 'Bayesian Lasso',
outfolder = "/results",
saveHyperParms=F,
saveExtraData = F,
type = 'BL',
stratified = T,
reps = 50,
folds = 10)
print(wb2)
res.no_noise.FAI2.bl <- GROAN.run(nds.no_noise.FAI2, wb2)
plotResult(res.no_noise.FAI2.bl)
#putting the results best index together for further analysis
res.total = rbind(res.no_noise.FAI2.bl, res.no_noise.FAI2)
#defaults is a boxplot of Pearson's correlations
p = plotResult(res.total)
print(p)
#a barplot with 95% confidence interval of Pearson's correlations
p = plotResult(res.total, plot.type = 'bar_conf95')
print(p)
plotResult(res.total, plot.type = 'bar', variable = 'time')
View(res.total)
View(res.total)
write.xlsx(res.total, "/results/BL_vs_rrBLUP_IndexDS.xlsx")
write.xlsx(res.total, "BL_vs_rrBLUP_IndexDS.xlsx")
p + coord_flip() +
theme_bw() +
labs(title = "Accuracies between models in the same Rust Index",
subtitle = "10 folds - 50 repetitions",
caption = "BL seems slightly better")
#defaults is a boxplot of Pearson's correlations
p = plotResult(res.total)
p + coord_flip() +
theme_bw() +
labs(title = "Accuracies between models in the same Rust Index",
subtitle = "10 folds - 50 repetitions",
caption = "BL seems slightly better")
p +
theme_bw() +
labs(title = "Accuracies between models in the same Rust Index",
subtitle = "10 folds - 50 repetitions",
caption = "BL seems slightly better")
p + geom_density()
plotResult(res.total1)
plotResult(res.total1) +
theme_bw() +
labs(title = "Accuracies between diferents Rust Indices",
subtitle = "10 folds - 50 repetitions",
caption = "FAI-BLUP without LP50 is better than the others")
View(res.total1)
write.xlsx(res.total1, "Accuracies_RustIndices_rrBLUP.xlsx")
