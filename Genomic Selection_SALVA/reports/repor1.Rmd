---
title: "CREA stay"
author: "Salvador Osuna-Caballero"
date: "6/12/2021"
output:
  html_document:
    toc: true
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

### Introduction

For three months, the PhD candidate Salvador Osuna-Caballero will be in CREA Lodi to learn bioinformatics tools to apply in his own data set. The main goal is to apply **Genomic Selection** models over those data to obtain results with high precision and accuracy.

### Material

A pea collection of 320 genotypes that include:

| Material      | n accessions (%) |
|---------------|------------------|
| Landrace      | 175 (54.7 %)     |
| Cultivar      | 47 (14.7 %)      |
| Wild          | 45 (14.1%)       |
| Unknown       | 44 (13.8 %)      |
| Breeding Line | 9 (2.8 %)        |

Of the following *Pissum* spp. taxa diversity:

| Taxa                                          | n accessions (%) |
|:----------------------------------------------|------------------|
| *Pisum sativum* ssp. *sativum*                | 231 (72.8 %)     |
| *Pisum sativum* ssp. *arvense*                | 27 (8.8 %)       |
| *Pisum sativum* ssp. *elatius*                | 22 (7.2 %)       |
| *Pisum fulvum*                                | 17 (5.0 %)       |
| *Pisum abyssinicum*                           | 12 (3.8 %)       |
| *Pisum sativum* ssp. *elatius* var. *pumilio* | 4 (1.3 %)        |
| *Pisum sativum* ssp. *transcaucasicum*        | 2 (0.6 %)        |
| *Pisum sativum* ssp. *choresmicum*            | 1 (0.3 %)        |
| *Pisum sativum* ssp. *cinereum*               | 1 (0.3 %)        |

Constituting of following worldwide panel:

![](WolrdWide_pea_panel.PNG "Worldwide Pisum spp. panel"){width="630"}

### Experimental designs

#### Field

The pea collection was phenotyped over three crop seasons (2017/18, 2018/19 and 2019/20) at Cordoba, Spain using the pea cv. Cartouche as control check for all the traits measured. Each field assays consist of a randomized complete block design (RCBD) based on alpha lattice model was performed with three replicates. The experimental unit consisted of a single 1 m long row per accession with 10 seeds per row, separated from the adjacent row by 0,7 m.

![*Simplified scheme of the experimental design in the field.*](Experimental_design_field.png){width="1000"}

##### Traits evaluated

-   [Germinated plants.]{.ul} For the ten seeds sown, how many of them germinated properly in the soil. (3 seasons)

-   [DtFF.]{.ul} Days to First Flower. Days from the sowing to the first flower appeared in the experimental unit. (2 seasons)

-   [GDDtFP.]{.ul} Growing Degree Days to First Flower. Accumulate temperature from the sowing to the first flower appeared in the experimental unit. (2 seasons)

-   [DtF.]{.ul} Days to Flowering. Days from the sowing to the 50 % flowering plants. (3 seasons)

-   [GDDtF.]{.ul} Growing Degree Days to Flowering. Accumulate temperature from the sowing to the 50% flowering plants. (3 seasons)

-   [DtFP.]{.ul} Days to First Pod. Days from the sowing to the first pod appeared in the experimental unit. (3 seasons)

-   [GDDtFP.]{.ul} Growing Degree Days to First Pod. Accumulate temperature from the sowing to the first pod appeared in the experimental unit. (3 seasons)

-   [DtP.]{.ul} Days to Podding. Days from the sowing to the 50 % podding plants. (3 seasons)

-   [GDDtP.]{.ul} Growing Degree Days to Podding. Accumulate temperature from the sowing to the 50% podding plants. (3 seasons)

-   [DtM.]{.ul} Days to Madurity. Days from the sowing to the 100 % pods are grain full. (2 seasons)

-   [GDDtM.]{.ul} Growing Degree Days to Podding. Accumulate temperature from the sowing to the100 % pods are grain full. (2 seasons)

-   [Biomass.]{.ul} Dry Biomass of the experimental unit in kg. Dry Biomass per plant is also included in an additional column in grams. (3 seasons)

-   [Yield.]{.ul} Total yield in kg of dry seeds. Yield per plant is also included in an additional column in grams. (3 seasons)

-   [ASCO.]{.ul} Ascochyta blights incidence over the experimental unit, calculated in percentage of canopy damage over the total plants. (2 seasons)

-   [POWDERY MILDEW.]{.ul} *Erysiphe pisi* incidence over the experimental unit, calculated in percentage of coverage by the fungus mycelium over the total plants. (2 seasons)

-   [RUST.]{.ul} *Uromyces pisi*, artificially inoculated to ensure the homogeneity of the disease, severity in the experimental unit. Calculated in coverage percentage by pustules over the plants. (3 seasons)

#### Growth Chamber (Controlled Conditions)

In this case the experimental unit consisted in a single plant evaluated per accession. In every rust inoculation, two replicates per accession were evaluated and two separated inoculations were carried out using the rust susceptible Messire cv. as control check.

##### Traits evaluated

-   IF. Infection frequency as number of pustules per cm^2^ of leaf, counted every day from day 7 after inoculation to day 14, when the life cycle of rust ended.

-   AUDPC. The IF measured every day allow to calculate the area under the disease progress curve.

-   LP~50~. The IF measured every day allow to calculate the latency period. It is the period time from the inoculation to the 50 % of total pustules appeared.

-   DS (%). The disease severity is a subjective estimation of the damage caused by rust. It is the percentage of pustules over the total plant.

-   IT. The infection type according to [@stackman1962identification]

## Tasks

### Task 1. Create a main folder

It is important to have the project well organized. So, the first step is create a folder with the following sub-folder:

-   Data

-   Scripts (.R files)

-   report (.Rmd, .html)

-   Results

-   Complementary folders (i.e.¬†bibliography)

This main folder containing all the project information needs a backup. I am currently using MEGA cloud but try to use GitHub is desirable.

### Task 2. Solve the ùõÇ lattice (Get rid of repetitions)

To solve the alpha lattice design the accessions are previously normalized with his control. (Create a function to automatize that process, with Excel is quietly long).

```{r, include= F}
library(metan)
library(readxl)
library(tidyverse)
library(ggstatsplot)
library(hrbrthemes)
R20 <- read_excel("~/GitHub/Genomic-Selection/Genomic Selection_SALVA/data/R18_19_20.xlsx", 
                     sheet = "R20", 
                     col_types = 
                       c("text", #ENV
                         "numeric", #REP
                         "numeric", #BLOCK
                         "numeric", #ROW
                         "text", #GEN
                         "numeric", #GERM
                         "numeric", #DtFF
                         "numeric", #GDD_FF
                         "numeric", #DtF
                         "numeric", #GDD_F
                         "numeric", #DtFP
                         "numeric", #GDD_FP
                         "numeric", #DtP
                         "numeric", #GDD_P
                         "numeric", #DtM
                         "numeric", #GDD_M
                         "numeric", #rustadj
                         "numeric", #asco_%
                         "numeric", #asco_adj
                         "numeric", #oidio_%
                         "numeric", #Oidio_adj
                         "numeric", #Biom_plant_g	
                         "numeric", #yield_plant_g
                         "numeric"  #yield_kgHa
                       )) 
```

```{r}
#Load as data frame:
R20 <- as.data.frame(R20)

head(R20)

```

```{r}
## Metan package allow to calculate BLUPs and others stability indexes and parameters. It also offers statistic help.
gen_alpha <- 
  gamem(R20, #data
        GEN, #genotype
        REP, #replicate
        c("GDD_DTFF", "GDD_DTF", "GDD_DTP", "GDD_DTM"), # fenology traits
        block = BLOCK) #block
```

```{r}
#plot(gen_alpha, type = "re")
get_model_data(gen_alpha)

```

```{r, fig.height= 10, fig.width= 8}
##BLUP histogram for phenology in 2018 season:
par(mfrow = c(4,2))

hist(gen_alpha$GDD_DTFF$BLUPgen$Predicted , main = "BLUP distribution of GDD_DTFF")
hist(R20$GDD_DTFF,  main = "RawData distribution of GDD_DTFF")

hist(gen_alpha$GDD_DTF$BLUPgen$Predicted , main = "BLUP distribution of GDD_DTF")
hist(R20$GDD_DTF,  main = "RawData distribution of GDD_DTF")

hist(gen_alpha$GDD_DTP$BLUPgen$Predicted , main = "BLUP distribution of GDD_DTP")
hist(R20$GDD_DTP,  main = "RawData distribution of GDD_DTP")

hist(gen_alpha$GDD_DTM$BLUPgen$Predicted , main = "BLUP distribution of GDD_DTM")
hist(R20$GDD_DTM,  main = "RawData distribution of GDD_DTM")
```

### Task 3. Create useful functions to recycle the console

Let's try to create a function to add automatically a new column in our data frame. That columns will be the observation (every row in the data frame) of a trait properly normalized with their row/block (in the field design) controls and the average of the trait in the ENV (environment). First, it is necessary to create the Correction Factor function:

$\frac{\overline{X}_{ENV}}{(\overline{X}_B + \overline{X}_R)/2} = CF_{B,R}$

Here, $CF_{B,R}$ is the Correction Factor for every observed trait, ${\overline{X}_{ENV}}$ is the total average for the trait. ${\overline{X}_{B}}$ is the average of the controls observed in the same trait of the Block and ${\overline{X}_{R}}$ is the average of the controls observed in the same trait of the Row. Every observation multiplied by his $CF_{B,R}$, means the value normalized in the new column.

First, create the matrix of $CF_{B,R}$ for every rep:

```{r, include = F}
#Create vectors with the block/row average for every REP:
GERM_B1 <- R20 %>%
  group_by(BLOCK) %>%
  filter(REP == "1") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(BLOCK)

GERM_B2 <- R20 %>%
  group_by(BLOCK) %>%
  filter(REP == "2") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(BLOCK)

GERM_B3 <- R20 %>%
  group_by(BLOCK) %>%
  filter(REP == "3") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(BLOCK)

GERM_R1 <- R20 %>%
  group_by(ROW) %>%
  filter(REP == "1") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(ROW)

GERM_R2 <- R20 %>%
  group_by(ROW) %>%
  filter(REP == "2") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(ROW)

GERM_R3 <- R20 %>%
  group_by(ROW) %>%
  filter(REP == "3") %>%
  filter(GEN == "Control") %>%
  summarise(Oidio = mean(Oidio)) %>%
  arrange(ROW)
```

```{r}
# Create a 19 x 19 matrix (of 19 rows and 19 blocks)
  #vector for every rep:
RowsR1 <- c(GERM_R1$Oidio)
BlocksR1 <- c(GERM_B1$Oidio)

my_matR1 <- matrix(nrow=max(R20$ROW), ncol=max(R20$BLOCK))
for (i in 1:length(RowsR1)){
  for (j in 1:length(BlocksR1)){
    my_matR1[i,j]<-(mean(R20$Oidio))/((RowsR1[i]+BlocksR1[j])/2)       
  }
}

format(round(my_matR1, 2), nsmall = 2) #show with two decimals

```

```{r, include=FALSE}
#The matrixes for Rep 2 and Rep 3

RowsR2 <- c(GERM_R2$Oidio)
BlocksR2 <- c(GERM_B2$Oidio)

RowsR3 <- c(GERM_R3$Oidio)
BlocksR3 <- c(GERM_B3$Oidio)

my_matR2 <- matrix(nrow=max(R20$ROW), ncol=max(R20$BLOCK))
for (i in 1:length(RowsR2)){
  for (j in 1:length(BlocksR2)){
    my_matR2[i,j]<-(mean(R20$Oidio))/((RowsR2[i]+BlocksR2[j])/2)       
  }
}
format(round(my_matR2, 2), nsmall = 2) #show with two decimals

my_matR3 <- matrix(nrow=max(R20$ROW), ncol=max(R20$BLOCK))
for (i in 1:length(RowsR3)){
  for (j in 1:length(BlocksR3)){
    my_matR3[i,j]<-(mean(R20$Oidio))/((RowsR3[i]+BlocksR3[j])/2)       
  }
}
format(round(my_matR3, 2), nsmall = 2) #show with two decimals
```

Now he have a matrix of 19 blocks x 19 rows equal to the experimental design for every replicate. To convert the matrix into a simple list to add in the original data frame:

```{r}
CF1<- as.tibble(unlist(c(my_matR1)))
```

```{r, include=FALSE}
CF2 <- as.tibble(unlist(c(my_matR2)))
CF3 <- as.tibble(unlist(c(my_matR3)))
```

The next step is to bind the three reps in one new column with the Correction Factor of a determined trait and multiply the specific CF by their observation value.

```{r}
FC_BIOM <- rbind(CF1, CF2, CF3)

R20_t <- R20 %>%
 mutate(OidioT = as.numeric(unlist(Oidio * FC_BIOM$value)))

head(R20_t)


```

```{r, warning=FALSE}
#Check the differences between values normalized and row values:
comparison <- data.frame(type = c(rep("Germ", 1083),rep("Germ_T", 1083)), 
               value = c(R18_t$T_Germ, R18_t$GERM_t))

p <- comparison %>%
  ggplot( aes(x=value, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity', bins = 10) +
  scale_fill_manual(values=c("#69b3a2", "#404080")) +
  theme_ipsum() +
  labs(fill="")
p
```

Finally, create a function to do automatically the previous work:

```{r}
F1 <- function(df, trait) {
  
  #Is there differences between REPs in the control for the trait selected??
  p <- df %>% filter(GEN == "Control") %>% ggbetweenstats(
    x     = REP,
    y     = {{trait}},
    title = c("Distribution of {{trait}} across Replicates in the Controls")
  )
  return(p)
  }
  
F2 <- function(df, trait) {
  #Create the vectors for the BLOCK/ROW average by REP
  trait_B1 <- df %>%
    group_by(BLOCK) %>%
    filter(REP == "1") %>%
    filter(GEN == "Control") %>%
    summarise(trait = mean({{trait}})) %>%
   arrange(BLOCK)

  trait_B2 <- df %>%
   group_by(BLOCK) %>%
   filter(REP == "2") %>%
   filter(GEN == "Control") %>%
   summarise(trait = mean({{trait}})) %>%
   arrange(BLOCK)

  trait_B3 <- df %>%
   group_by(BLOCK) %>%
   filter(REP == "3") %>%
   filter(GEN == "Control") %>%
   summarise(trait = mean({{trait}})) %>%
   arrange(BLOCK)

  trait_R1 <- df %>%
    group_by(ROW) %>%
    filter(REP == "1") %>%
    filter(GEN == "Control") %>%
    summarise(trait = mean({{trait}})) %>%
    arrange(ROW)

  trait_R2 <- df %>%
    group_by(ROW) %>%
    filter(REP == "2") %>%
    filter(GEN == "Control") %>%
    summarise(trait = mean({{trait}})) %>%
    arrange(ROW)

  trait_R3 <- df %>%
    group_by(ROW) %>%
    filter(REP == "3") %>%
    filter(GEN == "Control") %>%
    summarise(trait = mean({{trait}})) %>%
    arrange(ROW)

  #Create the matrixes with the CF for the trait selected:
  RowsR1 <- c(trait_R1$trait)
  BlocksR1 <- c(trait_B1$trait)
  
  RowsR2 <- c(trait_R2$trait)
  BlocksR2 <- c(trait_B2$trait)

  RowsR3 <- c(trait_R3$trait)
  BlocksR3 <- c(trait_B3$trait)
  
  mean_trait <- mean(df[,trait])
  
    my_matR1 <- matrix(nrow=max(df$ROW), ncol=max(df$BLOCK))
  for (i in 1:length(RowsR1)){
    for (j in 1:length(BlocksR1)){
      my_matR1[i,j] <- mean_trait/((RowsR1[i]+BlocksR1[j])/2)     
    }
  }
  
    my_matR2 <- matrix(nrow=max(df$ROW), ncol=max(df$BLOCK))
  for (i in 1:length(RowsR2)){
    for (j in 1:length(BlocksR2)){
      my_matR2[i,j]<-mean_trait/((RowsR2[i]+BlocksR2[j])/2)       
    }
  }
    
    my_matR3 <- matrix(nrow=max(df$ROW), ncol=max(df$BLOCK))
  for (i in 1:length(RowsR3)){
    for (j in 1:length(BlocksR3)){
     my_matR3[i,j]<-mean_trait/((RowsR3[i]+BlocksR3[j])/2)       
    }
  }
  
  #Convert the matrixes to one column to add it in the df  
  CF1<- as.tibble(unlist(c(my_matR1)))
  CF2 <- as.tibble(unlist(c(my_matR2)))
  CF3 <- as.tibble(unlist(c(my_matR3)))
  FC_trait <- rbind(c(CF1, CF2, CF3))

  #Add to the data frame the correction factor column and multiply by its trait, creating a new column
  
  
  #df <- df %>% mutate(trait_t = as.numeric(unlist({{trait}} * FC_trait)))
  dfnew <- df %>% mutate(trait_t = as.numeric(unlist(df[,trait])) * as.numeric(FC_BIOM$value))
  # mutate(yield_plant_gT = as.numeric(unlist(yield_plant_g * FC_BIOM$value)))
  
  return(dfnew)  
    
}
```

```{r}
F1(R20, Biom_plant_g)
```

```{r, warning=FALSE}
#Data frame with the new column "trait" normalized with the controls for that trait
newdf <- F2(df = R20, trait = "Biom_plant_g")
head(newdf)
```

```{r}
#Data frame with the new column "trait" normalized with the controls for that trait
newdf2 <- F2(R20, trait = "Oidio")
head(newdf2)
```

With the new function created is it possible to normalize the data of all the seasons with their controls. The next step is to explore the data, make some correlations and visualize them.

### Task 4. Start a report

Well... here we are...

## References
